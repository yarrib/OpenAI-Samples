{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9f8f5eb-de84-470a-831b-7072752cd190",
   "metadata": {},
   "source": [
    "## Basic gradio app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a4b0ab-c25d-437d-ad04-968b697f9860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gradio as gr\n",
    "\n",
    "from openai.embeddings_utils import distances_from_embeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# this openai api key should be saved in a local file named \".env\". It should also be put in the .gitignore to avoid sharing secrets\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "df=pd.read_csv('processed/embeddings.csv', index_col=0)\n",
    "# df.to_parquet('processed/embeddings.parquet')|\n",
    "\n",
    "\n",
    "df['embeddings'] = df['embeddings'].apply(eval).apply(np.array)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d507bf-f15b-4359-9687-b64a4975134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context(\n",
    "    question, df, max_len=1800, size=\"ada\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a context for a question by finding the most similar context from the dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the embeddings for the question\n",
    "    q_embeddings = openai.Embedding.create(input=question, engine='text-embedding-ada-002')['data'][0]['embedding']\n",
    "\n",
    "    # Get the distances from the embeddings\n",
    "    df['distances'] = distances_from_embeddings(q_embeddings, df['embeddings'].values, distance_metric='cosine')\n",
    "\n",
    "\n",
    "    returns = []\n",
    "    cur_len = 0\n",
    "\n",
    "    # Sort by distance and add the text to the context until the context is too long\n",
    "    for i, row in df.sort_values('distances', ascending=True).iterrows():\n",
    "        \n",
    "        # Add the length of the text to the current length\n",
    "        cur_len += row['n_tokens'] + 4\n",
    "        \n",
    "        # If the context is too long, break\n",
    "        if cur_len > max_len:\n",
    "            break\n",
    "        \n",
    "        # Else add it to the text that is being returned\n",
    "        returns.append(row[\"text\"])\n",
    "\n",
    "    # Return the context\n",
    "    return \"\\n\\n###\\n\\n\".join(returns)\n",
    "\n",
    "def answer_question(\n",
    "    df,\n",
    "    model=\"text-davinci-003\",\n",
    "    question=\"Am I allowed to publish model outputs to Twitter, without a human review?\",\n",
    "    max_len=1800,\n",
    "    size=\"ada\",\n",
    "    debug=False,\n",
    "    max_tokens=150,\n",
    "    stop_sequence=None,\n",
    "    temperature = 0.\n",
    "):\n",
    "    \"\"\"\n",
    "    Answer a question based on the most similar context from the dataframe texts\n",
    "    \"\"\"\n",
    "    context = create_context(\n",
    "        question,\n",
    "        df,\n",
    "        max_len=max_len,\n",
    "        size=size,\n",
    "    )\n",
    "    # If debug, print the raw model response\n",
    "    if debug:\n",
    "        print(\"Context:\\n\" + context)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    try:\n",
    "        # Create a completions using the question and context\n",
    "        response = openai.Completion.create(\n",
    "            prompt=f\"Answer the question in a convincing manner based on the context below, and if the question can't be answered based on the context, say \\\"I don't know\\\"\\n\\nContext: {context}\\n\\n---\\n\\nQuestion: {question}\\nAnswer:\",\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=stop_sequence,\n",
    "            model=model,\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12afe4b0-b5b3-47f1-9d51-7e5354138e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://dev.to/feranmiodugbemi/how-to-create-an-ai-powered-chatbot-with-gradio-and-openais-gpt-35-2c8l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95afd785-1f3d-49a6-ae60-92c6380639bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### import gradio as gr\n",
    "\n",
    "def text_to_text(input):\n",
    "    if input:\n",
    "        question = input\n",
    "        ans = answer_question(df, question=question)\n",
    "        return ans\n",
    "    \n",
    "def text_to_text(temp, text):\n",
    "    if text:\n",
    "        ans = answer_question(df, question=text, temperature=temp)\n",
    "        return ans\n",
    "    \n",
    "\n",
    "inputs = [gr.components.Slider(value = 0., minimum=0., maximum=1., step = 0.05, label=\"Temperature (0=most factual, 1=most creative)\")\n",
    "          , gr.components.Textbox(lines=4, label=\"Chat with Wipfli\")]\n",
    "outputs = gr.components.Textbox(label=\"Output\")\n",
    "examples = [[0.0, \"Where are wipfli's largest offices?\"],\n",
    " [1.0, \"Where are wipfli's wisconsin offices?\"],\n",
    " [0.25, 'Can wipfli help me with BI Services?'],\n",
    " [0.9,  'How can wipfli help me with BI Services for my manufacturing company?'],\n",
    " # [0.75, 'What is one Wipfli success story?'],\n",
    " [0.0, 'How do I get in touch with Wipfli?']\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a02054-880c-409f-a43a-3b2be3dfa2e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(answer_question(df, question=\"What services does wipfli provide?\",temperature=0.))\n",
    "print('*'*80)\n",
    "print(answer_question(df, question=\"What services does wipfli provide?\",temperature=1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1133623-927f-4c5f-892c-6dc76fd21709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gr.Interface(fn=text_to_text, inputs=inputs, outputs=outputs, title=\"wipfli website q&a\",\n",
    "             description=\"Ask any questions about Wipfli (public website)\", examples=examples,\n",
    "             theme=\"compact\").launch(share=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4cc61c-5d02-4920-b073-771aec67f044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
