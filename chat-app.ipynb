{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0a3e7ef-02ec-4b26-b85f-736b9b507706",
   "metadata": {},
   "source": [
    "## Creating a chatbot with OpenAI and gpt-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1861ac-7218-4d2f-a268-7aa2ba4735fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import openai\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# this openai api key should be saved in a local file named \".env\". It should also be put in the .gitignore to avoid sharing secrets\n",
    "openai.api_key =  os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "global init_state\n",
    "init_state = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "\n",
    "def chat_prompt(prompt, history, state):\n",
    "    print(history, state)\n",
    "    state = state if len(state) > 1 else init_state\n",
    "    history = history or []\n",
    "    dialog = {\"role\":\"user\", \"content\":prompt}\n",
    "    state.append(dialog)\n",
    "    return \"\", history + [[prompt, None]], state\n",
    "\n",
    "\n",
    "\n",
    "def bot(history, state):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=state,\n",
    "        temperature=1,\n",
    "        n=1,\n",
    "        stream=False,\n",
    "        max_tokens=200\n",
    "    )\n",
    "\n",
    "\n",
    "    content = response['choices'][0]['message']['content']\n",
    "    history += [[None,content]]\n",
    "    state.append({\"role\": \"assistant\", \"content\":content})\n",
    "\n",
    "    return history,state\n",
    "\n",
    "\n",
    "block = gr.Blocks()\n",
    "\n",
    "with block:\n",
    "    gr.Markdown(\"\"\"<h1><center> ChatGPT simple clone</center></h1>\"\"\")\n",
    "    gr.Markdown(\"\"\"this should work mostly like chat gpt, but might error out after a while due to history. If that happens try refreshing the page. Max tokens on a response is set to 200.\"\"\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    message=gr.Textbox(placeholder=\"type a message to get started...\")\n",
    "    clear = gr.Button(\"Clear Conversation\")\n",
    "    state = gr.State(value = init_state)\n",
    "    \n",
    "    # add .then to prune the chat if it gets too long as a 3rd step?\n",
    "    message.submit(chat_prompt, inputs=[message, chatbot, state], outputs=[message, chatbot, state], queue=False).then(bot, [chatbot,state], [chatbot,state])\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)#.then(gr.State(), init_state, state, queue=False)\n",
    "\n",
    "block.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a701fa3-f07c-48e8-baa5-78da55a4526d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
